{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UQdEH6XL-Hx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "QqN5v_TkXS4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "cl3u8cK--IPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "import tensorflow.keras\n",
        "import scipy as sp\n",
        "import tensorflow as tf\n",
        "import platform\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import BertTokenizer\n",
        "from transformers import TFBertModel # This will load the hugging face bert transformer and set it's parameters to tensorflow\n",
        "# import tensorflow_hub as hub # to load the bert directly from tensorflow hub, already compatible with tensorflow environment.\n",
        "import re\n",
        "import os"
      ],
      "metadata": {
        "id": "Fke7jB7i76Bz"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Datasets"
      ],
      "metadata": {
        "id": "OYUGNd-Z7fLb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr9w_FGU7K6Q",
        "outputId": "fb0a514a-1211-4de8-b942-cf9049b3b381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/ML_Advance/lab2_transfer_learning/data/')\n",
        "\n",
        "df = pd.read_csv('imdb.csv')"
      ],
      "metadata": {
        "id": "h_5xRr2Z7lnV"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.groupby('sentiment').count())\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20tI644H79NR",
        "outputId": "2c1ea215-84b9-43ee-af08-99d186a3b3a4"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           review\n",
            "sentiment        \n",
            "negative    25000\n",
            "positive    25000\n",
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_logical_devices('TPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnlQsG97pYMI",
        "outputId": "23614d19-9e6d-4a63-80e0-4739568ab232"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'),\n",
              " LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'),\n",
              " LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'),\n",
              " LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'),\n",
              " LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'),\n",
              " LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'),\n",
              " LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'),\n",
              " LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdWwuNJRTSGP",
        "outputId": "5b66d924-28c8-4b47-c9e8-9d8b624b8c6c"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.38.42.18:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num TPUs Available: \", len(tf.config.list_logical_devices('TPU')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efptT5G9YY3g",
        "outputId": "8e28a336-33e3-42d2-d9af-b9705f697aaa"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num TPUs Available:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess the dataset"
      ],
      "metadata": {
        "id": "t9tfMFC58g1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove Unwanted characters, and try to use only the first 20000 rows of the data to speed up our fine-tunning.\n",
        "- remove punctuation marks\n",
        "- remove characters which are not letters or digits\n",
        "- remove successive whitespaces\n",
        "- convert the text to lower case\n",
        "- strip whitespaces from the beginning and the end of the reviews"
      ],
      "metadata": {
        "id": "g_UtoZg-96MC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.head(20000)\n",
        "df.sentiment = [0 if s == 'negative' else 1 for s in df.sentiment]\n",
        "def process(x):\n",
        "    x = re.sub('[,\\.!?:()\"]', '', x)\n",
        "    x = re.sub('<.*?>', ' ', x)\n",
        "    x = re.sub('http\\S+', ' ', x)\n",
        "    x = re.sub('[^a-zA-Z0-9]', ' ', x)\n",
        "    x = re.sub('\\s+', ' ', x)\n",
        "    return x.lower().strip()\n",
        "\n",
        "df['review'] = df['review'].apply(lambda x: process(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CDXJPtF8kGF",
        "outputId": "e760f92b-1ef7-4852-f137-08ea716d10f4"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-120-6c7883b5864b>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.sentiment = [0 if s == 'negative' else 1 for s in df.sentiment]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot the data distribution over the labels\n",
        "- Determine how balance the dataset is."
      ],
      "metadata": {
        "id": "2NFF7Hsa-RhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.sentiment.head())\n",
        "print(df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGouvl3N-3-7",
        "outputId": "1fc76c60-e508-47a1-fae5-85f0ea2db28f"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    0\n",
            "4    1\n",
            "Name: sentiment, dtype: int64\n",
            "(20000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of sentences for each sentiment category\n",
        "positive_counts = len(df[df.sentiment == 1])\n",
        "negative_counts = len(df[df.sentiment == 0])\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(['Positive', 'Negative'], [positive_counts, negative_counts], color=['green', 'red'])\n",
        "plt.title('Distribution of Sentence Counts by Sentiment')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Sentence Counts')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "lnPzQ8P6-fUR",
        "outputId": "d01b0f4e-319d-4b89-9cdf-b8ea56f71d4c"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepare data for Bert, padding them (masking them appropriately)\n",
        "Let’s first see how the BERT tokenizer converts sentences into token ids. token ids : it is an integer that represents a particular token.\n",
        "\n",
        "**attention mask** : it is a sequence of ones and zeroes to tell the model which token comes from input sentence (segment id =1) and which are just padding token(segment id =0).\n",
        "\n",
        "**padding** : when we train BERT model we make sure that every input to the model should have same size that means same length of inputs so that the model can perform back propagation efficiently but all our input which are review text can not be in same size, some can be small review and some can be large. Padding is the technique where we make our entire review in the same size but first we have to decide a fixed length or max_length."
      ],
      "metadata": {
        "id": "4pOfcI_xANhj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Split our dataset into 80/20\n",
        "- Since these dataset is balanced and have enough dataset for splitting, it make sense that we can use 80/20"
      ],
      "metadata": {
        "id": "JDWv8Kr1AyCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, test_size=0.2)\n",
        "\n",
        "train_sentences = train.review\n",
        "train_labels = train.sentiment\n",
        "test_sentences = test.review\n",
        "test_labels = test.sentiment\n",
        "\n",
        "\n",
        "print(train_sentences.shape, test_sentences.shape)\n",
        "print(train_labels.shape, test_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6aXOFBSAcjX",
        "outputId": "9c33a615-acdd-492d-e6d0-4d5b89a5eb20"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16000,) (4000,)\n",
            "(16000,) (4000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Masking and Padding dataset\n",
        "Hugging face library provides another function called tokenizer.encode_plus() which we will use to perform almost entire preprocessing steps in one go. It\n",
        "\n",
        "converts reviews into tokens\n",
        "adds [CLS] token at the beginning of input\n",
        "performs padding if sequence length is less than max_len\n",
        "performs truncation if sequence length is greater than max_len\n",
        "adds [SEP] token at the end of sequence."
      ],
      "metadata": {
        "id": "lOi-BxTGD83s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    # Load the BERT tokenizer\n",
        "    print('Loading BERT tokenizer...')\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCrQuaAlEEO7",
        "outputId": "a1450b30-861e-4b39-cdc3-b63f1dbba26a"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512\n",
        "EPOCCH = 30\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "PhBwgVCoW1jC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "# def generate_data(data,labels):\n",
        "#   input_ids = []\n",
        "#   attention_masks = []\n",
        "\n",
        "#   for sent in data:\n",
        "#       # `encode_plus` will:\n",
        "#       #   (1) Tokenize the sentence.\n",
        "#       #   (2) Prepend the `[CLS]` token to the start.\n",
        "#       #   (3) Append the `[SEP]` token to the end.\n",
        "#       #   (4) Map tokens to their IDs.\n",
        "#       #   (5) Pad or truncate the sentence to `max_length`\n",
        "#       #   (6) Create attention masks for [PAD] tokens.\n",
        "#       encoded_dict = tokenizer.encode_plus(\n",
        "#                           sent,                      # Sentence to encode.\n",
        "#                           add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "#                           max_length = 64,           # Pad & truncate all sentences.\n",
        "#                           pad_to_max_length = True,\n",
        "#                           return_attention_mask = True,   # Construct attn. masks.\n",
        "#                           truncation = True,\n",
        "#                           return_tensors = 'tf',     # Return pytorch tensors.\n",
        "#                     )\n",
        "\n",
        "#       # Add the encoded sentence to the list.\n",
        "#       input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "#       # And its attention mask (simply differentiates padding from non-padding).\n",
        "#       attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "#   # Convert the lists into tf.\n",
        "#   # this can be a duplicate since we're already returning tensorflow tensors.\n",
        "#   # input_ids = tf.convert_to_tensor(input_ids)\n",
        "#   # attention_masks = tf.convert_to_tensor(attention_masks)\n",
        "#   labels = tf.convert_to_tensor(labels)\n",
        "\n",
        "#   return input_ids, attention_masks, labels"
      ],
      "metadata": {
        "id": "eUPp-qhzEG8W"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data(data, labels):\n",
        "    \"\"\"Generates tf.data.Dataset from input data.\"\"\"\n",
        "    print(\"tokenizing...\")\n",
        "    X_train = tokenizer(\n",
        "          text=data.tolist(),\n",
        "          add_special_tokens=True,\n",
        "          max_length=MAX_LEN,\n",
        "          pad_to_max_length=True\n",
        "          truncation=True,\n",
        "          padding=True,\n",
        "          return_tensors='tf',\n",
        "          return_token_type_ids=False,\n",
        "          return_attention_mask=True,\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "    labels = tf.convert_to_tensor(labels)\n",
        "\n",
        "    return X_train, labels"
      ],
      "metadata": {
        "id": "yIEcSZAAD_RF"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "with strategy.scope():\n",
        "  tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "  train_ds, train_labels = generate_data(train_sentences, train_labels)\n",
        "  test_ds, test_labels = generate_data(test_sentences, test_labels)\n",
        "\n",
        "  print(train_ds)\n",
        "  print(train_labels)\n",
        "  print(test_ds)\n",
        "  print(test_labels)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2baYmnOmGozl",
        "outputId": "a000f479-6beb-4664-f8e1-118e5d865d45"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizing...\n",
            "tokenizing...\n",
            "{'input_ids': <tf.Tensor: shape=(16000, 70), dtype=int32, numpy=\n",
            "array([[  101,  1045,  3685, ...,  2052,  3891,   102],\n",
            "       [  101,  1045,  2018, ..., 12689, 13764,   102],\n",
            "       [  101,  3348,  2080, ..., 22917,  2839,   102],\n",
            "       ...,\n",
            "       [  101,  1996,  2060, ...,  7935,  2003,   102],\n",
            "       [  101,  1045,  5993, ...,  1997,  2184,   102],\n",
            "       [  101,  5261,  4670, ...,  2023,  9200,   102]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(16000, 70), dtype=int32, numpy=\n",
            "array([[1, 1, 1, ..., 1, 1, 1],\n",
            "       [1, 1, 1, ..., 1, 1, 1],\n",
            "       [1, 1, 1, ..., 1, 1, 1],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 1, 1, 1],\n",
            "       [1, 1, 1, ..., 1, 1, 1],\n",
            "       [1, 1, 1, ..., 1, 1, 1]], dtype=int32)>}\n",
            "tf.Tensor([0 0 0 ... 0 0 0], shape=(16000,), dtype=int64)\n",
            "{'input_ids': <tf.Tensor: shape=(4000, 70), dtype=int32, numpy=\n",
            "array([[  101,  2066,  2116, ...,  4458,  1998,   102],\n",
            "       [  101,  2023,  3185, ...,  1055,  9951,   102],\n",
            "       [  101,  1037,  3143, ...,  3787,  2008,   102],\n",
            "       ...,\n",
            "       [  101, 10468,  1045, ...,  2718,  3937,   102],\n",
            "       [  101,  1037,  2200, ...,  2080,  1998,   102],\n",
            "       [  101,  7929,  2023, ...,     0,     0,     0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(4000, 70), dtype=int32, numpy=\n",
            "array([[1, 1, 1, ..., 1, 1, 1],\n",
            "       [1, 1, 1, ..., 1, 1, 1],\n",
            "       [1, 1, 1, ..., 1, 1, 1],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 1, 1, 1],\n",
            "       [1, 1, 1, ..., 1, 1, 1],\n",
            "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}\n",
            "tf.Tensor([1 0 0 ... 1 1 0], shape=(4000,), dtype=int64)\n",
            "CPU times: user 1min 39s, sys: 0 ns, total: 1min 39s\n",
            "Wall time: 1min 38s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the Model and set it up for Feature space transfers"
      ],
      "metadata": {
        "id": "myWQnRapC11C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the bert directly from the hugging face and it'll be initialize to tensorflow for compatibility\n",
        "with strategy.scope():\n",
        "  bert_model = TFBertModel.from_pretrained('bert-base-uncased', trainable=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2XlbfTtJMCl",
        "outputId": "9bd30fae-ecbf-480f-d39c-bc0451bae2d5"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "def save_bottleneck_features(ds, labels, filename_addendum):\n",
        "    \"\"\"Saves bottleneck features extracted from a frozen BERT model.\"\"\"\n",
        "    bottleneck_features = []\n",
        "    labels_train = []\n",
        "    i = 1\n",
        "    with strategy.scope():\n",
        "      print(f'Extracting bottleneck features for {filename_addendum}')\n",
        "      bottleneck_features.extend(bert_model(ds)['pooler_output'].numpy())\n",
        "\n",
        "      print(f'Extending labels into numpy feature space for {filename_addendum}')\n",
        "      # Get the labels as well\n",
        "      labels_train.extend(labels)\n",
        "\n",
        "      bottleneck_features = np.array(bottleneck_features)\n",
        "      labels_train = np.array(labels_train)\n",
        "\n",
        "      print(f'Saving bottleneck features for {filename_addendum}')\n",
        "      np.save(f'./bottleneck_features_{filename_addendum}.npy', bottleneck_features)\n",
        "      np.save(f'./bottleneck_labels_{filename_addendum}.npy', labels_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW6ev3abJZOc",
        "outputId": "43c520df-a3a7-4830-e467-7bdd129dfb2c"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 18 µs, sys: 4 µs, total: 22 µs\n",
            "Wall time: 42.7 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap the feature extraction function within the TPU strategy scope\n",
        "with strategy.scope():\n",
        "    # Save training features\n",
        "    print('Saving bottleneck features (train)...')\n",
        "    save_bottleneck_features(train_ds, train_labels, 'train')\n",
        "\n",
        "    # Save validation features\n",
        "    print('Saving bottleneck features (test)...')\n",
        "    save_bottleneck_features(test_ds, test_labels, 'test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZc9ldkjvh_I",
        "outputId": "3ddace34-07da-430f-e307-d2acdc691414"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving bottleneck features (train)...\n",
            "Saving bottleneck features (test)...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train a classifier layer with extracted features\n",
        "- Now we can train our classifier with the extracted features\n",
        "- The classifier is simply a fully connected layer with 256 hidden units"
      ],
      "metadata": {
        "id": "UrHIDZZbZZRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "with strategy.scope():\n",
        "  print('Building text classification model...')\n",
        "  top_model = tf.keras.Sequential(name='imdb_classifier')\n",
        "\n",
        "  # Flatten the embedded sequence into a dense vector\n",
        "  top_model.add(layers.Flatten(name='flatten_layer'))\n",
        "\n",
        "  # Fully connected layers with activation functions and dropout\n",
        "  top_model.add(layers.Dense(256, activation='relu', name='dense_1'))\n",
        "  top_model.add(layers.Dropout(0.5))\n",
        "  top_model.add(layers.Dense(128, activation='relu', name='dense_2'))\n",
        "  top_model.add(layers.Dropout(0.2))\n",
        "\n",
        "  # Output layer with sigmoid for binary classification\n",
        "  top_model.add(layers.Dense(1, activation='sigmoid', name='output_layer'))\n",
        "\n",
        "  # Compile the model with appropriate loss and metrics\n",
        "  top_model.compile(optimizer='adam',\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Ks1HkpkBaKKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d99a8fa8-194c-4f8b-aedb-fc2b74f7cac2"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building text classification model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train the top model"
      ],
      "metadata": {
        "id": "MuDl4bREaf-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Load the foundational model saved feature space"
      ],
      "metadata": {
        "id": "YpJeS45gN0hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  # Load bottleneck features that have already been extracted by base model\n",
        "  train_data = np.load('./bottleneck_features_train.npy')\n",
        "  # the first half of labels are sharks, and second half are dolphins\n",
        "  train_labels = np.load('./bottleneck_labels_train.npy')\n",
        "  print('Training Data Shape: ',train_data.shape, 'Training Label Shape: ',train_labels.shape)\n",
        "\n",
        "  validation_data = np.load('./bottleneck_features_test.npy')\n",
        "  # the first half of labels are sharks, and second half are dolphins\n",
        "  validation_labels = np.load('./bottleneck_labels_test.npy')\n",
        "  print('Val Data Shape: ',validation_data.shape, 'Val Label Shape: ', validation_labels.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6sXjx0HNw7k",
        "outputId": "ecf652cd-ba1a-48be-fcf6-410e9e3c933e"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Shape:  (16000, 768) Training Label Shape:  (16000,)\n",
            "Val Data Shape:  (4000, 768) Val Label Shape:  (4000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Define the directory where you want to save the checkpoint file\n",
        "checkpoint_dir = '/content/drive/My Drive/ML_Advance/lab2_transfer_learning/checkpoints/'\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# Define the directory where you want to save the top model weights and model itself\n",
        "top_model_dir = '/content/drive/My Drive/ML_Advance/lab2_transfer_learning/models/top_model/'\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(top_model_dir, exist_ok=True)\n",
        "\n",
        "# Train model\n",
        "with strategy.scope():\n",
        "    # setup params and where to save features\n",
        "    epochs = 30\n",
        "    batch_size = 64\n",
        "\n",
        "    print('Training top model, saving the checkpoint...')\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(checkpoint_dir, 'checkpoint_{epoch:02d}.h5'),\n",
        "        save_weights_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        save_best_only=True)\n",
        "\n",
        "    print('Training transfer model from bottleneck...')\n",
        "    history = top_model.fit(train_data, train_labels,\n",
        "                            epochs=epochs,\n",
        "                            batch_size=batch_size,\n",
        "                            callbacks=[model_checkpoint_callback],\n",
        "                            validation_data=(validation_data, validation_labels),\n",
        "                            verbose=1)\n",
        "\n",
        "    print('Training complete.')\n",
        "\n",
        "     # Save top model weights\n",
        "    print('Saving top model weights...')\n",
        "    top_model_weights_path = os.path.join(top_model_dir, 'top_model_weights.h5')\n",
        "    top_model.save_weights(top_model_weights_path)\n",
        "\n",
        "    # Save the entire top model\n",
        "    print('Saving the top model...')\n",
        "    top_model.save(os.path.join(top_model_dir, 'top_model.h5'))\n",
        "    print('Done!')"
      ],
      "metadata": {
        "id": "rTCnm6Gkaj8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be9a7e4-58c3-4121-bde8-ef7f6bcaa1c7"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training top model, saving the checkpoint...\n",
            "Training transfer model from bottleneck...\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.5414 - accuracy: 0.6858 - val_loss: 0.5433 - val_accuracy: 0.7548\n",
            "Training complete.\n",
            "Saving top model weights...\n",
            "Saving the top model...\n",
            "Done!\n",
            "CPU times: user 2.58 s, sys: 384 ms, total: 2.97 s\n",
            "Wall time: 5.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot the result"
      ],
      "metadata": {
        "id": "Ew3oZhSid4yW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_validation_acc(history, smooth=False, smooth_factor=0.8):\n",
        "    def smooth_curve(points, factor=0.8):\n",
        "        smoothed_points = []\n",
        "        for point in points:\n",
        "            if smoothed_points:\n",
        "                previous = smoothed_points[-1]\n",
        "                smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "            else:\n",
        "                smoothed_points.append(point)\n",
        "        return smoothed_points\n",
        "\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    if smooth:\n",
        "        acc = smooth_curve(acc)\n",
        "        val_acc = smooth_curve(val_acc)\n",
        "        loss = smooth_curve(loss)\n",
        "        val_loss = smooth_curve(val_loss)\n",
        "\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "dDQpHLdrd3PW"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_validation_acc(history)"
      ],
      "metadata": {
        "id": "4j2KuwqlWiOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fine-Tune the bert\n",
        "- unfreeze 1 layer of bert and try to combine all the models together and train them, comparing it's performance with the old one."
      ],
      "metadata": {
        "id": "Z6v-agxodjCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# # Define function to unfreeze the last layer\n",
        "# def unfreeze_last_layer(model):\n",
        "#   \"\"\"Unfreezes the last layer of a BERT model (classification head).\"\"\"\n",
        "#   set_trainable = False\n",
        "#   for layer in model.bert.encoder.layer[-1:]:\n",
        "#     for param in layer.parameters:\n",
        "#       param.requires_grad = True\n",
        "\n",
        " # make it work correctly with a TensorFlow/Keras BERT model loaded from Hugging Face Transformers.\n",
        "def unfreeze_last_layer(model):\n",
        "    \"\"\"Unfreezes the last layer of a BERT model (classification head).\"\"\"\n",
        "    model.trainable = False  # Set the entire model as non-trainable\n",
        "    for layer in model.layers:\n",
        "        if 'bert' in layer.name:  # Check if the layer belongs to the BERT model\n",
        "            for sub_layer in layer.layers[-1:]:  # Unfreeze the last layer of the BERT model\n",
        "                sub_layer.trainable = True"
      ],
      "metadata": {
        "id": "IEWkT0OQgJBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "#\n",
        "# Fine tune top bert 1st layer (classifier layer)\n",
        "#\n",
        "\n",
        "print('Building combined model...')\n",
        "\n",
        "# add the model on top of the top model base\n",
        "model = tf.keras.Model(inputs=bert_model.input,\n",
        "              outputs=top_model(bert_model.output))\n",
        "\n",
        "\n",
        "\n",
        "# now let's fine tune one layer within Bert\n",
        "# Freeze all blocks up to first layer (the block we are fine tuning)\n",
        "unfreeze_last_layer(bert_model)\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "seCSd14bdyqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = 'models/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "print('Fine tuning combined model...')\n",
        "history = model.fit(train_ds,\n",
        "              epochs=epochs,\n",
        "              batch_size=16,\n",
        "              callbacks=[model_checkpoint_callback],\n",
        "              validation_data=test_ds,\n",
        "              verbose=1)"
      ],
      "metadata": {
        "id": "nSzwWUlTgzRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot the result of the fine tuned model."
      ],
      "metadata": {
        "id": "Zh-6Qz3mhRFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_validation_acc(history, smooth=True)"
      ],
      "metadata": {
        "id": "twfGXvv2hbG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(val_ds)\n",
        "print('test acc:', test_acc)"
      ],
      "metadata": {
        "id": "EUG64jOJhnAL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}